{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e612c3-56aa-44a5-a27c-c570ed8e8ef6",
   "metadata": {},
   "source": [
    "```r\n",
    "ds = read.csv(\"buy.csv\", header=T)\n",
    "\n",
    "# income 의 합 : 반복문 이용\n",
    "total = 0\n",
    "\n",
    "for(i in 1:nrow(ds)) {\n",
    "  total = total + ds$income[i]\n",
    "}\n",
    "\n",
    "# income 의 합 : 함수 이용\n",
    "\n",
    "total = sum(ds$income)\n",
    "------------------------\n",
    "# if 문\n",
    "ds = read.csv(\"buy.csv\", header=T, sep=',')\n",
    "\n",
    "\n",
    "if( nrow(ds) > 100) {\n",
    "  print(\"The number of data > 100\")\n",
    "} else {\n",
    "  print(\"The number of data <= 100\")\n",
    "}\n",
    "\n",
    "혹은 조건문 확장을 위해서 else if를 사용할 수 있음\n",
    "파이썬 : elif\n",
    "줄리아 : elseif\n",
    "R : else if\n",
    "\n",
    "\n",
    "# ('T', 'F') ⇌ (0, 1) 형태로 변환\n",
    "ds\\$buy = ifelse(ds\\$buy == 0, 'T', 'F')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb034bf5-5201-4d86-848f-7779b64eb00d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742fc38-51b4-4bd1-adf5-15dedbcc68ba",
   "metadata": {},
   "source": [
    "```python\n",
    "ds = pd.read_csv('buy.csv', header=0, sep=\",\")\n",
    "\n",
    "# income의 합을 for문으로 구해보기 (without 내장함수)\n",
    "total = 0\n",
    "\n",
    "for i in range(0, len(ds)) :\n",
    "\ttotal = total + ds.loc[i, 'income']\n",
    "\n",
    "\n",
    "# income 의 합 : 함수 이용\n",
    "total = ds['income'].sum()\n",
    "\n",
    "# 파이썬에서 특정 칼럼 불러오기\n",
    "- ds['income']\n",
    "- ds[['income']]\n",
    "- ds.income\n",
    "\n",
    "ds = pd.read_csv('buy.csv', header=0, sep=\",\")\n",
    "\n",
    "if (len(ds) > 100) :\n",
    "    print(\"The number of data > 100\")\n",
    "else : # 조건문 확장하려면 elif로 가능하다. \n",
    "    print(\"The number of data <= 100\")\n",
    "\n",
    "\n",
    "# ('T', 'F') ⇌ (0, 1) 형태로 변환\n",
    "ds['buy'] = ds['buy'].apply(lambda x: 'T' if x==0 else 'F')\n",
    "\n",
    "# lambda안에서도 출력에 if문을 걸어줄 수 있음\n",
    "# \"lambda\" 는 런타임에 생성해서 사용할 수 있는 익명 함수\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39845a-4864-4043-bc0a-c96918967f72",
   "metadata": {},
   "source": [
    "```r\n",
    "ds = read.csv(\"buy.csv\", header=T)\n",
    "\n",
    "# buy==1인 경우의 income의 합 계산 (반복문과 함께 이용)\n",
    "total = 0\n",
    "\n",
    "for(i in 1:nrow(ds)){\n",
    "  if (ds[i, 3]==1) {\n",
    "    total = total + ds[i, 6]    \n",
    "  }\n",
    "}\n",
    "\n",
    "ds = read.csv(\"buy.csv\", header=T)\n",
    "\n",
    "# buy==1인 경우의 행을 뽑아서 tdata에 추가해주기\n",
    "tdata = c()\n",
    "\n",
    "for(i in 1:nrow(ds)) {\n",
    "  if (ds$buy[i]==1) {\n",
    "    tdata = rbind(tdata, ds[i,])\n",
    "  }\n",
    "}\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "# 2개의 파일에서 데이터를 읽어와 binding\n",
    "get_data <- function(file_name, item_no){\n",
    "ds = read.csv(file_name, header=T)\n",
    "sub_data = subset(ds, itemno==item_no)  \n",
    "  # itemno라는 칼럼명이 있음\n",
    "  return (sub_data)\n",
    "}\n",
    "\n",
    "<***subset***>\n",
    "- 설정하는 조건에 맞는 벡터, 매트릭스, 혹은 데이터 프레임을 반환한다. \n",
    "- 기본 형태\n",
    "  - subset(x,subset, select)\n",
    "  - x에는 벡터, 매트릭스 혹은 데이터프레임을 반환함.\n",
    "  - select는 열을 가지고 있는 데이터프레임에만 적용(dplyr의 filter 함수와 같이 결과값 중에서 select로 지정한 열만 반환한다.)\n",
    "  - 아래와 같이 사용 가능\n",
    "  - subset(diamonds, cut=='Premium' & color=='E', select= clarity)\n",
    "  - 따라서 해당 조건을 만족하는 칼럼중에 clarity라는 열만 추출할 수 있음.\n",
    "  - 제외하려면 !=을 사용해주면 된다. \n",
    "\n",
    "\n",
    "\n",
    "f_n = \"func_ex1.csv\"\n",
    "i_no = 21\n",
    "data1 = get_data(f_n, i_no)\n",
    "\n",
    "f_n = \"func_ex2.csv\"\n",
    "i_no = 21\n",
    "data2 = get_data(f_n, i_no)\n",
    "\n",
    "data = rbind(data1, data2)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0c038-532d-4792-a0c3-435510344cbc",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "\n",
    "# 2개의 파일에서 데이터를 읽어와 binding\n",
    "def get_data (file_name, item_no) :\n",
    "    ds = pd.read_csv(file_name, header=0, sep=',')\n",
    "    sub_data = ds[ds.itemno == item_no]\n",
    "    # ds.itemno == item_no를 통해 bool형태를 그냥 []안에\n",
    "    # 넣어주기만 하면 된다. \n",
    "    # 만족하는 행이 다 불러와질 것이다. \n",
    "    \n",
    "    return (sub_data)\n",
    "\n",
    "\n",
    "f_n = \"func_ex1.csv\"\n",
    "i_no = 21\n",
    "data1 = get_data (f_n, i_no)\n",
    "\n",
    "f_n = \"func_ex2.csv\"\n",
    "i_no = 21\n",
    "data2 = get_data(f_n, i_no)\n",
    "\n",
    "data = pd.concat([data1, data2])\n",
    "# pandas의 concat 사용할 때, `list`안에 넣어준다 !!!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eba5df-8fd1-4b03-8658-33fdf39a8f30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bc99c-d695-4608-aa8b-53d7aadd89d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46838a58-8f5f-46df-9078-0fa2d609d95a",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "library(rvest)      \n",
    "library(tidyverse) \n",
    "library(stringr)\n",
    "\n",
    "# paste : 나열된 원소 사이에 공백을 두고 결과값을 출력한다.\n",
    "# paste0 : 나열된 원소 사이에 공백없이 출력한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pages = 1\n",
    "url = \"https://finance.naver.com/sise/sise_market_sum.nhn?&page=\"\n",
    "url = paste0(url, pages)\n",
    "\n",
    "\n",
    "# 웹 페이지 read \n",
    "html <- read_html(url, encoding=\"euc-kr\")\n",
    "\n",
    "# 주식 기본 정보 읽기\n",
    "\n",
    "corp = html %>% html_nodes(\".tltle\") %>% html_text()\n",
    "code = html %>% html_nodes(\"td\") %>% html_nodes(\"a\") %>% html_attr(\"href\")\n",
    "code = code[str_detect(code, \"item\")]\n",
    "# str_detect : 문자열 찾는 함수\n",
    "# str_detect(벡터, 찾고자하는 문자)\n",
    "# 반환값은 bool형태\n",
    "\n",
    "# 추가적으로 내가 찾고자하는 문자만! 추출하고 싶을 땐,\n",
    "# 벡터 %in% '원하는 문자'\n",
    "# 벡터[벡터 %in% '원하는 문자']로 추출할 수 있음\n",
    "# str_detect는 찾고자 하는 문자만 추출하는 게 아니라 곽도성사람, 곽도성사람3 이런거까지 출력됨.\n",
    "# %in%을 사용하면 곽도성으로만 이루어진 단어를 추출함.\n",
    "\n",
    "code <- str_sub(code, -6, -1)\n",
    "# 부분 추출하기\n",
    "# str_sub(string, start, end)\n",
    "# 지금 -6,-1은 파이썬에서의 index처럼 생각해도 된다. \n",
    "\n",
    "\n",
    "\n",
    "code <- code[c(TRUE, FALSE)]\n",
    "\n",
    "data <- html %>%html_nodes(\".number\") %>%html_text() %>%parse_number() #drops any non-numeric characters before or after the first number\n",
    "\n",
    "data_name <- html %>%html_nodes(\"th\") %>%html_text()\n",
    "var_names <- data_name[3:12]\n",
    "df <- data.frame(matrix(data, ncol = length(var_names), byrow = T))\n",
    "names(df) <- var_names\n",
    "df$corp <- corp   \n",
    "df$code <- code   \n",
    "\n",
    "df <- df %>% select(corp, code, everything())\n",
    "# df에서 corp,code순으로 우선 정렬하겠다.\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0c88a-478e-4312-9a1e-fb1999ba30ef",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "\n",
    "### Method 1\n",
    "import pandas as pd \n",
    "import requests \n",
    "\n",
    "page=1\n",
    "url = \"https://finance.naver.com/sise/sise_market_sum.nhn?page=“\n",
    "url = url + str(page)\n",
    "\n",
    "html = requests.get(url) \n",
    "table = pd.read_html(html.text)\n",
    "\n",
    "data1 = table[1].dropna(thresh=7).reset_index(drop=True)\n",
    "\n",
    "page=2\n",
    "url = \"https://finance.naver.com/sise/sise_market_sum.nhn?page=“\n",
    "url = url + str(page)\n",
    "html = requests.get(url) \n",
    "table = pd.read_html(html.text)\n",
    "data2 = table[1].dropna(thresh=7).reset_index(drop = True)\n",
    "\n",
    "data = pd.concat([data1, data2])\n",
    "data\n",
    "data.to_excel('c.xlsx')\n",
    "\n",
    "data = data.iloc[:, 0:12]\n",
    "data.to_excel('c.xlsx', index=False)\n",
    "\n",
    "# for문을 이용해서 여러 페이지를 읽어올 수 있다. \n",
    "\n",
    "\n",
    "\n",
    "### Method 2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=1\n",
    "url = \"https://finance.naver.com/sise/sise_market_sum.nhn?page=“\n",
    "url = url + str(page)\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "#print (soup)\n",
    "stock_head = soup.find(\"thead\").find_all(\"th\")\n",
    "data_head = [head.get_text() for head in stock_head]\n",
    "#print(data_head)\n",
    "stock_list = soup.find(\"table\", attrs={\"class\": \"type_2\"}).find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "from pandas import DataFrame\n",
    "data = []\n",
    "for stock in stock_list:\n",
    "     if len(stock) > 1 :\n",
    "            data=data+[stock.get_text().split()]\n",
    "data = DataFrame(data, columns=['N','종목명',\n",
    "     '현재가','전일비','등락률','액면가','시가총액',\n",
    "     '상장주식수','외국인비율','거래량’\n",
    "     ,'PER','ROE'])\n",
    "data.to_excel('c2.xlsx', index=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
